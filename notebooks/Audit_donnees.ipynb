{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6295ebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a54050f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(\"../data\")\n",
    "\n",
    "# Note the Capital Letters and correct filenames\n",
    "TRAIN_PATH = data_path / \"Train.csv\"\n",
    "TEST_PATH  = data_path / \"Test.csv\"\n",
    "SUB_PATH   = data_path / \"SampleSubmission.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd520a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(data_path.exists())\n",
    "print(TRAIN_PATH.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ea10941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (29132, 29)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(TRAIN_PATH)\n",
    "print(\"train shape:\", train.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2e4131b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  shape: (10000, 29)\n"
     ]
    }
   ],
   "source": [
    "test  = pd.read_csv(TEST_PATH)\n",
    "print(\"test  shape:\", test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b81d043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub   shape: (210000, 2)\n"
     ]
    }
   ],
   "source": [
    "sub   = pd.read_csv(SUB_PATH)\n",
    "print(\"sub   shape:\", sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b50c8bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# verifieons qu'on a les memes colonnes dans train et test\n",
    "assert list(train.columns) == list(test.columns), \"Train/Test: colonnes différentes (problème de schéma).\"\n",
    "\n",
    "# verifieons qu'on a pas de valeurs manquantes\n",
    "assert train[\"ID\"].isna().sum() == 0\n",
    "assert test[\"ID\"].isna().sum() == 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e87e00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>join_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>branch_code</th>\n",
       "      <th>occupation_code</th>\n",
       "      <th>occupation_category_code</th>\n",
       "      <th>P5DA</th>\n",
       "      <th>RIBP</th>\n",
       "      <th>...</th>\n",
       "      <th>AHXO</th>\n",
       "      <th>BSTQ</th>\n",
       "      <th>FM3X</th>\n",
       "      <th>K6QO</th>\n",
       "      <th>QBOL</th>\n",
       "      <th>JWFN</th>\n",
       "      <th>JZ9D</th>\n",
       "      <th>J9JW</th>\n",
       "      <th>GHYX</th>\n",
       "      <th>ECY3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4WKQSBB</td>\n",
       "      <td>1/2/2019</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "      <td>1987</td>\n",
       "      <td>1X1H</td>\n",
       "      <td>2A7I</td>\n",
       "      <td>T4MS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CP5S02H</td>\n",
       "      <td>1/6/2019</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "      <td>1981</td>\n",
       "      <td>UAOD</td>\n",
       "      <td>2A7I</td>\n",
       "      <td>T4MS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2YKDILJ</td>\n",
       "      <td>1/6/2013</td>\n",
       "      <td>M</td>\n",
       "      <td>U</td>\n",
       "      <td>1991</td>\n",
       "      <td>748L</td>\n",
       "      <td>QZYX</td>\n",
       "      <td>90QI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID join_date sex marital_status  birth_year branch_code  \\\n",
       "0  4WKQSBB  1/2/2019   F              M        1987        1X1H   \n",
       "1  CP5S02H  1/6/2019   F              M        1981        UAOD   \n",
       "2  2YKDILJ  1/6/2013   M              U        1991        748L   \n",
       "\n",
       "  occupation_code occupation_category_code  P5DA  RIBP  ...  AHXO  BSTQ  FM3X  \\\n",
       "0            2A7I                     T4MS     0     0  ...     0     0     0   \n",
       "1            2A7I                     T4MS     0     0  ...     0     0     0   \n",
       "2            QZYX                     90QI     0     0  ...     0     0     0   \n",
       "\n",
       "   K6QO  QBOL  JWFN  JZ9D  J9JW  GHYX  ECY3  \n",
       "0     1     0     0     0     0     0     0  \n",
       "1     1     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0     1  \n",
       "\n",
       "[3 rows x 29 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74f46275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb colonnes profil : 8\n",
      "Nb colonnes produits: 21\n",
      "Produits: ['P5DA', 'RIBP', '8NN1', '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9', 'N2MW', 'AHXO', 'BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', 'ECY3']\n"
     ]
    }
   ],
   "source": [
    "PROFILE_COLS = [\n",
    "    \"ID\", \"join_date\", \"sex\", \"marital_status\", \"birth_year\",\n",
    "    \"branch_code\", \"occupation_code\", \"occupation_category_code\"\n",
    "]\n",
    "\n",
    "PRODUCT_COLS = [c for c in train.columns if c not in PROFILE_COLS]\n",
    "\n",
    "print(\"Nb colonnes profil :\", len(PROFILE_COLS))\n",
    "print(\"Nb colonnes produits:\", len(PRODUCT_COLS))\n",
    "print(\"Produits:\", PRODUCT_COLS)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f62a08f",
   "metadata": {},
   "source": [
    "Ici, la particularité est que la cible n’est pas donnée directement : dans le fichier Test,un produit que le client possède réellement  a été masqué en remplaçant un 1 par 0 dans les 21 produits.\n",
    "Le but du modèle est donc de retrouver quel produit a été caché.\n",
    "Le “masque”, c’est juste cette opération : prendre un produit détenu (1) et le mettre à 0 pour simuler un “produit manquant”.\n",
    "On doit le faire aussi sur Train (pour créer un apprentissage supervisé), sinon le modèle apprend sur des paniers “complets” et il sera en décalage avec Test où un produit est manquant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae390bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_basket = train[PRODUCT_COLS].sum(axis=1)\n",
    "test_basket  = test[PRODUCT_COLS].sum(axis=1)\n",
    "\n",
    "train_basket.name = \"basket_size_train\"\n",
    "test_basket.name  = \"basket_size_test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cfdb85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basket size (train) - describe:\n",
      " count    29132.000000\n",
      "mean         2.277667\n",
      "std          0.602677\n",
      "min          2.000000\n",
      "25%          2.000000\n",
      "50%          2.000000\n",
      "75%          2.000000\n",
      "max         14.000000\n",
      "Name: basket_size_train, dtype: float64\n",
      "\n",
      "Basket size (test)  - describe:\n",
      " count    10000.00000\n",
      "mean         1.28530\n",
      "std          0.59088\n",
      "min          1.00000\n",
      "25%          1.00000\n",
      "50%          1.00000\n",
      "75%          1.00000\n",
      "max          7.00000\n",
      "Name: basket_size_test, dtype: float64\n",
      "\n",
      "Mean gap (train - test): 0.99\n"
     ]
    }
   ],
   "source": [
    "print(\"Basket size (train) - describe:\\n\", train_basket.describe())\n",
    "print(\"\\nBasket size (test)  - describe:\\n\", test_basket.describe())\n",
    "\n",
    "mean_gap = round(float(train_basket.mean() - test_basket.mean()),2)\n",
    "print(\"\\nMean gap (train - test):\", mean_gap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1188107e",
   "metadata": {},
   "source": [
    "Le résultat Mean gap (train - test): 0.99 signifie qu’en moyenne, les clients du Test ont ~1 produit “1” de moins que ceux du Train. C’est exactement le pattern attendu car un produit  a été masqué (remplacer un 1 par 0) dans Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1213a9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Min train basket: 2  / Min test basket: 1\n",
      "Nb train basket_size==0: 0\n",
      "Nb test  basket_size==0: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMin train basket:\", int(train_basket.min()), \" / Min test basket:\", int(test_basket.min()))\n",
    "print(\"Nb train basket_size==0:\", int((train_basket == 0).sum()))\n",
    "print(\"Nb test  basket_size==0:\", int((test_basket  == 0).sum()))\n",
    "\n",
    "assert (train_basket >= 1).all(), \"Train: clients avec 0 produit → surprenant (à investiguer).\"\n",
    "assert (test_basket  >= 1).all(), \"Test: clients avec 0 produit → incompatible avec masking '1 produit'.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff469c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répartition basket_size (train) - top 15:\n",
      "basket_size_train\n",
      "2     22732\n",
      "3      5169\n",
      "4       916\n",
      "5       215\n",
      "6        71\n",
      "7        22\n",
      "8         5\n",
      "9         1\n",
      "14        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Répartition basket_size (train) - top 15:\")\n",
    "print(train_basket.value_counts().sort_index().head(15))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c7783c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Répartition basket_size (test)  - top 15:\n",
      "basket_size_test\n",
      "1    7685\n",
      "2    1921\n",
      "3     287\n",
      "4      76\n",
      "5      26\n",
      "6       4\n",
      "7       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRépartition basket_size (test)  - top 15:\")\n",
    "print(test_basket.value_counts().sort_index().head(15))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "001fac8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nb lignes train avec basket_size == 1: 0\n",
      "Nb lignes test  avec basket_size == 1: 7685\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNb lignes train avec basket_size == 1:\", int((train_basket == 1).sum()))\n",
    "print(\"Nb lignes test  avec basket_size == 1:\", int((test_basket  == 1).sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "281801dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La colonne est souvent nommée exactement comme ça\n",
    "assert \"ID X PCODE\" in sub.columns, \"SampleSubmission: colonne 'ID X PCODE' manquante.\"\n",
    "assert \"Label\" in sub.columns, \"SampleSubmission: colonne 'Label' manquante.\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bcdaf06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb IDs dans submission: 10000\n",
      "Nb produits distincts: 21\n",
      "Répartition nb lignes par ID (doit être constant):\n",
      "21    10000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "tmp = sub[\"ID X PCODE\"].astype(str).str.split(\" X \", expand=True)\n",
    "tmp.columns = [\"ID\", \"PCODE\"]\n",
    "\n",
    "print(\"Nb IDs dans submission:\", tmp[\"ID\"].nunique())\n",
    "print(\"Nb produits distincts:\", tmp[\"PCODE\"].nunique())\n",
    "print(\"Répartition nb lignes par ID (doit être constant):\")\n",
    "print(tmp.groupby(\"ID\").size().value_counts().head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0230a96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assertions structurelles\n",
    "assert tmp[\"ID\"].nunique() == test[\"ID\"].nunique(), \"Submission: nb IDs != nb IDs test.\"\n",
    "assert set(tmp[\"PCODE\"].unique()) == set(PRODUCT_COLS), \"Submission: produits != colonnes produits du dataset.\"\n",
    "assert (tmp.groupby(\"ID\").size() == len(PRODUCT_COLS)).all(), \"Submission: chaque ID doit avoir exactement 21 lignes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4a167b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year_from_join_date(s: str) -> float:\n",
    "    \"\"\"\n",
    "    Extraction  de l'année (on ne fait PAS confiance au jour/mois car format ambigu).\n",
    "    Retourne np.nan si pas d'année.\n",
    "    \"\"\"\n",
    "    if pd.isna(s):\n",
    "        return np.nan\n",
    "    m = re.search(r\"(\\d{4})\", str(s))\n",
    "    return float(m.group(1)) if m else np.nan\n",
    "\n",
    "\n",
    "def assert_products_binary(df: pd.DataFrame, product_cols: list[str], df_name: str) -> None:\n",
    "    bad = {}\n",
    "    for c in product_cols:\n",
    "        vals = set(pd.unique(df[c].dropna()))\n",
    "        if not vals.issubset({0, 1}):\n",
    "            bad[c] = sorted(list(vals))[:10]\n",
    "    assert len(bad) == 0, f\"{df_name}: colonnes produits non binaires détectées: {bad}\"\n",
    "\n",
    "\n",
    "def unknown_categories_report(train_df: pd.DataFrame, test_df: pd.DataFrame, cat_cols: list[str]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for col in cat_cols:\n",
    "        tr = set(train_df[col].dropna().astype(str).unique())\n",
    "        te = set(test_df[col].dropna().astype(str).unique())\n",
    "        unseen = sorted(list(te - tr))\n",
    "        rows.append({\n",
    "            \"col\": col,\n",
    "            \"train_unique\": len(tr),\n",
    "            \"test_unique\": len(te),\n",
    "            \"unseen_in_train_count\": len(unseen),\n",
    "            \"unseen_examples\": unseen[:10]\n",
    "        })\n",
    "    return pd.DataFrame(rows).sort_values(\"unseen_in_train_count\", ascending=False)\n",
    "\n",
    "\n",
    "def age_at_join_report(df: pd.DataFrame, df_name: str) -> pd.Series:\n",
    "    join_year = df[\"join_date\"].apply(extract_year_from_join_date)\n",
    "    birth_year = pd.to_numeric(df[\"birth_year\"], errors=\"coerce\")\n",
    "    age = join_year - birth_year\n",
    "    age = age.dropna()\n",
    "    print(f\"{df_name}: join_year NaN:\", int(join_year.isna().sum()))\n",
    "    return age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "68700e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>join_date_missing</th>\n",
       "      <th>join_year_missing</th>\n",
       "      <th>join_year_min</th>\n",
       "      <th>join_year_max</th>\n",
       "      <th>ambiguous_day_month_share</th>\n",
       "      <th>part1_gt12_share</th>\n",
       "      <th>part2_gt12_share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset  join_date_missing  join_year_missing  join_year_min  join_year_max  \\\n",
       "0   train                  2                  2         2010.0         2020.0   \n",
       "1    test                  1                  1         2010.0         2020.0   \n",
       "\n",
       "   ambiguous_day_month_share  part1_gt12_share  part2_gt12_share  \n",
       "0                   0.999863          0.000137               0.0  \n",
       "1                   0.999900          0.000100               0.0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def join_date_audit(df: pd.DataFrame, name: str) -> pd.DataFrame:\n",
    "    s = df[\"join_date\"]\n",
    "    join_year = s.apply(extract_year_from_join_date)\n",
    "\n",
    "    # Parsing \"naïf\" des 2 premiers champs pour mesurer l'ambiguïté\n",
    "    tmp = s.dropna().astype(str).str.split(\"/\", expand=True)\n",
    "    tmp.columns = [\"part1\", \"part2\", \"part3\"]\n",
    "    tmp[\"part1\"] = pd.to_numeric(tmp[\"part1\"], errors=\"coerce\")\n",
    "    tmp[\"part2\"] = pd.to_numeric(tmp[\"part2\"], errors=\"coerce\")\n",
    "    tmp[\"year\"]  = pd.to_numeric(tmp[\"part3\"], errors=\"coerce\")\n",
    "\n",
    "    ambiguous = ((tmp[\"part1\"] <= 12) & (tmp[\"part2\"] <= 12)).mean()  # jour/mois indiscernables\n",
    "    day_gt12  = (tmp[\"part1\"] > 12).mean()  # indique souvent \"jour d'abord\"\n",
    "    month_gt12 = (tmp[\"part2\"] > 12).mean() # indiquerait \"mois d'abord\" (rare ici)\n",
    "\n",
    "    report = pd.DataFrame([{\n",
    "        \"dataset\": name,\n",
    "        \"join_date_missing\": int(s.isna().sum()),\n",
    "        \"join_year_missing\": int(join_year.isna().sum()),\n",
    "        \"join_year_min\": float(np.nanmin(join_year.values)),\n",
    "        \"join_year_max\": float(np.nanmax(join_year.values)),\n",
    "        \"ambiguous_day_month_share\": float(ambiguous),\n",
    "        \"part1_gt12_share\": float(day_gt12),\n",
    "        \"part2_gt12_share\": float(month_gt12),\n",
    "    }])\n",
    "    return report, join_year\n",
    "\n",
    "train_join_report, train_join_year = join_date_audit(train, \"train\")\n",
    "test_join_report,  test_join_year  = join_date_audit(test,  \"test\")\n",
    "\n",
    "pd.concat([train_join_report, test_join_report], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ecddd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top missing (train):\n",
      " join_date                   0.000069\n",
      "ID                          0.000000\n",
      "sex                         0.000000\n",
      "marital_status              0.000000\n",
      "birth_year                  0.000000\n",
      "branch_code                 0.000000\n",
      "occupation_code             0.000000\n",
      "occupation_category_code    0.000000\n",
      "P5DA                        0.000000\n",
      "RIBP                        0.000000\n",
      "dtype: float64\n",
      "\n",
      "Top missing (test):\n",
      " join_date                   0.0001\n",
      "ID                          0.0000\n",
      "sex                         0.0000\n",
      "marital_status              0.0000\n",
      "birth_year                  0.0000\n",
      "branch_code                 0.0000\n",
      "occupation_code             0.0000\n",
      "occupation_category_code    0.0000\n",
      "P5DA                        0.0000\n",
      "RIBP                        0.0000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 1) Missing values\n",
    "missing_train = train.isna().mean().sort_values(ascending=False)\n",
    "missing_test  = test.isna().mean().sort_values(ascending=False)\n",
    "\n",
    "print(\"Top missing (train):\\n\", missing_train.head(10))\n",
    "print(\"\\nTop missing (test):\\n\", missing_test.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ee160c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) Produits binaires (assertions)\n",
    "assert_products_binary(train, PRODUCT_COLS, \"train\")\n",
    "assert_products_binary(test,  PRODUCT_COLS, \"test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c82421bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: join_year NaN: 2\n",
      "test: join_year NaN: 1\n",
      "\n",
      "Age at join (train):\n",
      " count    29130.000000\n",
      "mean        38.201716\n",
      "std          9.251233\n",
      "min          8.000000\n",
      "25%         31.000000\n",
      "50%         38.000000\n",
      "75%         45.000000\n",
      "max         80.000000\n",
      "dtype: float64\n",
      "\n",
      "Age at join (test):\n",
      " count    9999.000000\n",
      "mean       38.028303\n",
      "std         9.202317\n",
      "min        17.000000\n",
      "25%        31.000000\n",
      "50%        37.000000\n",
      "75%        45.000000\n",
      "max        87.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 3) join_date -> join_year (robuste) + âge à l'entrée\n",
    "age_train = age_at_join_report(train, \"train\")\n",
    "age_test  = age_at_join_report(test,  \"test\")\n",
    "\n",
    "print(\"\\nAge at join (train):\\n\", age_train.describe())\n",
    "print(\"\\nAge at join (test):\\n\",  age_test.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88677dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Anomalies âge (train):\n",
      "  age < 16: 2\n",
      "  age < 18: 7\n",
      "  age > 90: 0\n",
      "\n",
      "Anomalies âge (test):\n",
      "  age < 16: 0\n",
      "  age < 18: 3\n",
      "  age > 90: 0\n"
     ]
    }
   ],
   "source": [
    "# Compteurs d'anomalies (tu ajusteras les seuils selon la réalité métier)\n",
    "print(\"\\nAnomalies âge (train):\")\n",
    "print(\"  age < 16:\", int((age_train < 16).sum()))\n",
    "print(\"  age < 18:\", int((age_train < 18).sum()))\n",
    "print(\"  age > 90:\", int((age_train > 90).sum()))\n",
    "\n",
    "print(\"\\nAnomalies âge (test):\")\n",
    "print(\"  age < 16:\", int((age_test < 16).sum()))\n",
    "print(\"  age < 18:\", int((age_test < 18).sum()))\n",
    "print(\"  age > 90:\", int((age_test > 90).sum()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0fc45ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>train_unique</th>\n",
       "      <th>test_unique</th>\n",
       "      <th>unseen_in_train_count</th>\n",
       "      <th>unseen_examples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>occupation_code</td>\n",
       "      <td>233</td>\n",
       "      <td>187</td>\n",
       "      <td>9</td>\n",
       "      <td>[0FOI, 0ZND, 8CHJ, 93OJ, 9F96, BIA0, E2MJ, HSI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>marital_status</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>[F]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sex</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>branch_code</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>occupation_category_code</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        col  train_unique  test_unique  unseen_in_train_count  \\\n",
       "3           occupation_code           233          187                      9   \n",
       "1            marital_status             8            8                      1   \n",
       "0                       sex             2            2                      0   \n",
       "2               branch_code            15           15                      0   \n",
       "4  occupation_category_code             6            6                      0   \n",
       "\n",
       "                                     unseen_examples  \n",
       "3  [0FOI, 0ZND, 8CHJ, 93OJ, 9F96, BIA0, E2MJ, HSI...  \n",
       "1                                                [F]  \n",
       "0                                                 []  \n",
       "2                                                 []  \n",
       "4                                                 []  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4) Catégories inconnues en test (problème prod classique)\n",
    "CAT_COLS = [\"sex\", \"marital_status\", \"branch_code\", \"occupation_code\", \"occupation_category_code\"]\n",
    "unk_df = unknown_categories_report(train, test, CAT_COLS)\n",
    "unk_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1130508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top outliers (train):\n",
      " ID                          0\n",
      "join_date                   0\n",
      "sex                         0\n",
      "marital_status              0\n",
      "birth_year                  0\n",
      "branch_code                 0\n",
      "occupation_code             0\n",
      "occupation_category_code    0\n",
      "P5DA                        0\n",
      "RIBP                        0\n",
      "dtype: int64\n",
      "\n",
      "Top outliers (test):\n",
      " ID                          0\n",
      "join_date                   0\n",
      "sex                         0\n",
      "marital_status              0\n",
      "birth_year                  0\n",
      "branch_code                 0\n",
      "occupation_code             0\n",
      "occupation_category_code    0\n",
      "P5DA                        0\n",
      "RIBP                        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 2) Outliers\n",
    "outliers_train = train.isin([np.inf, -np.inf]).sum().sort_values(ascending=False)\n",
    "outliers_test  = test.isin([np.inf, -np.inf]).sum().sort_values(ascending=False)\n",
    "\n",
    "print(\"Top outliers (train):\\n\", outliers_train.head(10))\n",
    "print(\"\\nTop outliers (test):\\n\", outliers_test.head(10))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "352beeff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates (train): 0\n",
      "Duplicates (test): 0\n"
     ]
    }
   ],
   "source": [
    "# 3) Duplicates\n",
    "duplicates_train = train.duplicated().sum()\n",
    "duplicates_test  = test.duplicated().sum()\n",
    "\n",
    "print(\"Duplicates (train):\", duplicates_train)\n",
    "print(\"Duplicates (test):\", duplicates_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "988f7c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types (train):\n",
      " int64     22\n",
      "object     7\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Data types (test):\n",
      " int64     22\n",
      "object     7\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4) Data types\n",
    "data_types_train = train.dtypes.value_counts()\n",
    "data_types_test  = test.dtypes.value_counts()\n",
    "\n",
    "print(\"Data types (train):\\n\", data_types_train)\n",
    "print(\"\\nData types (test):\\n\", data_types_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16d581e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>train_unique</th>\n",
       "      <th>test_unique</th>\n",
       "      <th>unseen_in_train_count</th>\n",
       "      <th>unseen_examples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>occupation_code</td>\n",
       "      <td>233</td>\n",
       "      <td>187</td>\n",
       "      <td>9</td>\n",
       "      <td>[0FOI, 0ZND, 8CHJ, 93OJ, 9F96, BIA0, E2MJ, HSI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>marital_status</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>[F]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sex</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>branch_code</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>occupation_category_code</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        col  train_unique  test_unique  unseen_in_train_count  \\\n",
       "3           occupation_code           233          187                      9   \n",
       "1            marital_status             8            8                      1   \n",
       "0                       sex             2            2                      0   \n",
       "2               branch_code            15           15                      0   \n",
       "4  occupation_category_code             6            6                      0   \n",
       "\n",
       "                                     unseen_examples  \n",
       "3  [0FOI, 0ZND, 8CHJ, 93OJ, 9F96, BIA0, E2MJ, HSI...  \n",
       "1                                                [F]  \n",
       "0                                                 []  \n",
       "2                                                 []  \n",
       "4                                                 []  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def unseen_categories_report(train_df: pd.DataFrame, test_df: pd.DataFrame, cat_cols: list[str]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for col in cat_cols:\n",
    "        tr = set(train_df[col].dropna().astype(str).unique())\n",
    "        te = set(test_df[col].dropna().astype(str).unique())\n",
    "        unseen = sorted(list(te - tr))\n",
    "        rows.append({\n",
    "            \"col\": col,\n",
    "            \"train_unique\": len(tr),\n",
    "            \"test_unique\": len(te),\n",
    "            \"unseen_in_train_count\": len(unseen),\n",
    "            \"unseen_examples\": unseen[:10]\n",
    "        })\n",
    "    return pd.DataFrame(rows).sort_values(\"unseen_in_train_count\", ascending=False)\n",
    "\n",
    "unseen_df = unseen_categories_report(train, test, CAT_COLS)\n",
    "unseen_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "68bc99be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>age_missing</th>\n",
       "      <th>age_min</th>\n",
       "      <th>age_p1</th>\n",
       "      <th>age_p50</th>\n",
       "      <th>age_p99</th>\n",
       "      <th>age_max</th>\n",
       "      <th>age_lt_18</th>\n",
       "      <th>age_gt_90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset  age_missing  age_min  age_p1  age_p50  age_p99  age_max  age_lt_18  \\\n",
       "0   train            2      8.0    21.0     38.0     59.0     80.0          7   \n",
       "1    test            1     17.0    21.0     37.0     59.0     87.0          3   \n",
       "\n",
       "   age_gt_90  \n",
       "0          0  \n",
       "1          0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def age_audit(df: pd.DataFrame, join_year: pd.Series, name: str) -> pd.DataFrame:\n",
    "    birth_year = pd.to_numeric(df[\"birth_year\"], errors=\"coerce\")\n",
    "    age = join_year - birth_year\n",
    "\n",
    "    report = pd.DataFrame([{\n",
    "        \"dataset\": name,\n",
    "        \"age_missing\": int(age.isna().sum()),\n",
    "        \"age_min\": float(np.nanmin(age.values)),\n",
    "        \"age_p1\": float(np.nanpercentile(age.values, 1)),\n",
    "        \"age_p50\": float(np.nanpercentile(age.values, 50)),\n",
    "        \"age_p99\": float(np.nanpercentile(age.values, 99)),\n",
    "        \"age_max\": float(np.nanmax(age.values)),\n",
    "        \"age_lt_18\": int((age < 18).sum()),\n",
    "        \"age_gt_90\": int((age > 90).sum()),\n",
    "    }])\n",
    "    return report, age\n",
    "\n",
    "train_age_report, train_age = age_audit(train, train_join_year, \"train\")\n",
    "test_age_report,  test_age  = age_audit(test,  test_join_year,  \"test\")\n",
    "\n",
    "pd.concat([train_age_report, test_age_report], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "754f79b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: tous les produits sont strictement binaires (0/1).\n"
     ]
    }
   ],
   "source": [
    "def assert_products_binary(df: pd.DataFrame, product_cols: list[str], name: str) -> None:\n",
    "    bad = {}\n",
    "    for c in product_cols:\n",
    "        vals = set(pd.unique(df[c].dropna()))\n",
    "        if not vals.issubset({0, 1}):\n",
    "            bad[c] = sorted(list(vals))[:10]\n",
    "    assert len(bad) == 0, f\"{name}: colonnes produits non binaires détectées: {bad}\"\n",
    "\n",
    "assert_products_binary(train, PRODUCT_COLS, \"train\")\n",
    "assert_products_binary(test,  PRODUCT_COLS, \"test\")\n",
    "\n",
    "print(\"OK: tous les produits sont strictement binaires (0/1).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "20361a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_join_year(df: pd.DataFrame, join_year_fill: float) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out[\"join_year\"] = out[\"join_date\"].apply(extract_year_from_join_date)\n",
    "    out[\"join_year_missing\"] = out[\"join_year\"].isna().astype(int)\n",
    "    out[\"join_year\"] = out[\"join_year\"].fillna(join_year_fill)\n",
    "    return out\n",
    "\n",
    "def clean_age_at_join(df: pd.DataFrame, min_age: int = 18, max_age: int = 90) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    birth_year = pd.to_numeric(out[\"birth_year\"], errors=\"coerce\")\n",
    "    age = out[\"join_year\"] - birth_year\n",
    "\n",
    "    out[\"age_at_join_raw\"] = age\n",
    "    out[\"age_missing\"] = age.isna().astype(int)\n",
    "\n",
    "    # clip + flag\n",
    "    age_clipped = age.clip(lower=min_age, upper=max_age)\n",
    "    out[\"age_was_clipped\"] = ((age_clipped != age) & (~age.isna())).astype(int)\n",
    "    out[\"age_at_join\"] = age_clipped\n",
    "\n",
    "    return out\n",
    "\n",
    "def clean_categoricals_with_unknown(train_df: pd.DataFrame, df: pd.DataFrame, cat_cols: list[str]) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    for col in cat_cols:\n",
    "        out[col] = out[col].astype(str)\n",
    "        out[col] = out[col].replace({\"nan\": \"UNKNOWN\"})\n",
    "        known = set(train_df[col].dropna().astype(str).unique())\n",
    "        out[col] = out[col].where(out[col].isin(known), \"UNKNOWN\")\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f54bf275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>join_year_missing</th>\n",
       "      <th>age_missing</th>\n",
       "      <th>age_was_clipped</th>\n",
       "      <th>unknown_marital_status</th>\n",
       "      <th>unknown_occupation_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_clean</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_clean</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset  join_year_missing  age_missing  age_was_clipped  \\\n",
       "0  train_clean                  2            0                7   \n",
       "1   test_clean                  1            0                3   \n",
       "\n",
       "   unknown_marital_status  unknown_occupation_code  \n",
       "0                       0                        0  \n",
       "1                       1                       10  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join_year_fill: médiane train (robuste)\n",
    "join_year_fill = float(pd.Series(train[\"join_date\"].apply(extract_year_from_join_date)).dropna().median())\n",
    "\n",
    "train_clean = train.copy()\n",
    "test_clean  = test.copy()\n",
    "\n",
    "train_clean = clean_join_year(train_clean, join_year_fill)\n",
    "test_clean  = clean_join_year(test_clean,  join_year_fill)\n",
    "\n",
    "train_clean = clean_age_at_join(train_clean, min_age=18, max_age=90)\n",
    "test_clean  = clean_age_at_join(test_clean,  min_age=18, max_age=90)\n",
    "\n",
    "train_clean = clean_categoricals_with_unknown(train_clean, train_clean, CAT_COLS)\n",
    "test_clean  = clean_categoricals_with_unknown(train_clean, test_clean,  CAT_COLS)\n",
    "\n",
    "# Mini bilan\n",
    "def summarize_cleaning(df: pd.DataFrame, name: str) -> pd.DataFrame:\n",
    "    return pd.DataFrame([{\n",
    "        \"dataset\": name,\n",
    "        \"join_year_missing\": int(df[\"join_year_missing\"].sum()),\n",
    "        \"age_missing\": int(df[\"age_missing\"].sum()),\n",
    "        \"age_was_clipped\": int(df[\"age_was_clipped\"].sum()),\n",
    "        \"unknown_marital_status\": int((df[\"marital_status\"] == \"UNKNOWN\").sum()),\n",
    "        \"unknown_occupation_code\": int((df[\"occupation_code\"] == \"UNKNOWN\").sum()),\n",
    "    }])\n",
    "\n",
    "pd.concat([summarize_cleaning(train_clean, \"train_clean\"),\n",
    "           summarize_cleaning(test_clean,  \"test_clean\")], ignore_index=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
